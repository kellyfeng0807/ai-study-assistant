"""
AI Service - DeepSeek API Integration & Qwen-VL Integration
"""

import os
import json
import re
from openai import OpenAI
from dashscope import MultiModalConversation

class AIService:
    def __init__(self):
        self.client = OpenAI(
            api_key=os.environ.get('DEEPSEEK_API_KEY','sk-44838ffc3bb645e6a82dc24e55183bec'),
            base_url="https://api.deepseek.com"
        )
        self.dashscope_api_key = os.getenv("DASHSCOPE_API_KEY", "sk-52e14360ea034580a43eee057212de78")
    
    def generate_mindmap_mermaid(self, topic, depth=3, context='', style='TD'):
        """
        ä½¿ç”¨DeepSeekç”ŸæˆMermaidæ€ç»´å¯¼å›¾ä»£ç 
        style: 'TD' (top-down), 'LR' (left-right), 'radial' (radial/divergent)
        
        Temperatureè®¾ç½®è¯´æ˜(å®˜æ–¹æ¨è):
        - Data Cleaning/Data Analysis: 1.0 (æ€ç»´å¯¼å›¾ç”Ÿæˆå±äºæ•°æ®åˆ†æç±»ä»»åŠ¡)
        - éœ€è¦åœ¨å‡†ç¡®æ€§å’Œåˆ›é€ æ€§ä¹‹é—´å–å¾—å¹³è¡¡
        """
        # æ ¹æ®æ ·å¼è®¾ç½®ä¸åŒçš„ç³»ç»Ÿæç¤º
        if style == 'radial':
            system_prompt = """You are a mind map generation assistant. Generate Mermaid MINDMAP syntax for radial mind maps.

CRITICAL: Use Mermaid's native mindmap syntax following official specification.

MINDMAP SYNTAX RULES (from https://mermaid.js.org/syntax/mindmap.html):
1. Start with 'mindmap' keyword
2. Root node: root((text)) - use circle shape
3. Shape options for child nodes:
   - Square brackets: [text]
   - Rounded: (text)
   - Circle: ((text))
   - Cloud: )text(
   - Hexagon: {{text}}
   - Bang: ))text((
   - Default: text
4. Indentation: Use exactly 2 spaces per level (strict)
5. Icons: ::icon(fa fa-icon-name) on same line after text
6. All siblings MUST be at exact same indentation

LABEL TEXT SAFETY RULES (CRITICAL to prevent parse errors):
- NO parentheses ( ) inside labels - they conflict with shape syntax
- NO square brackets [ ] inside labels - they conflict with shape syntax
- NO curly braces { } inside labels - they conflict with shape syntax
- NO special math symbols: Ï€, Â², Â³, Î±, Î², Î³, Î¸, âˆ‘, âˆ«, â‰ˆ, â‰ , â‰¤, â‰¥
- NO punctuation that could be operators: <, >, ~, |, &, ^
- Use simple alternatives:
  * "power of 2" or "squared" instead of Â²
  * "pi" instead of Ï€
  * "theta" instead of Î¸
  * "approximately" instead of â‰ˆ
  * "not equal" instead of â‰ 
- For equations: use plain text like "E equals mc squared" or "z equals r times e to the i theta"
- Keep labels simple, descriptive, use common words
- If technical terms needed, use plain English/Chinese descriptions

STRUCTURE PRINCIPLES for balanced distribution:
- Root level: root((Topic))
- Level 1: 4-8 main branches using (Branch) or [Branch]
- Level 2: 2-4 items per branch
- Level 3: 1-3 items per level 2 item
- Keep branches balanced - similar number of children
- Use shape variety: alternate between (text) and [text] for level 1

EXAMPLE with proper structure:
mindmap
  root((Central Idea))
    (Branch Alpha)
      Item A1
      Item A2
      Item A3
    [Branch Beta]
      Item B1
      Item B2
    (Branch Gamma)
      Item C1
      Item C2
      Item C3
    [Branch Delta]
      Item D1
      Item D2

OUTPUT: Only mindmap code, no ```mermaid blocks, no explanations"""
        else:
            graph_direction = 'TD' if style == 'TD' else 'LR'
            system_prompt = f"""You are a mind map generation assistant. Generate Mermaid syntax for HIERARCHICAL mind maps.

CRITICAL SYNTAX RULES (must follow strictly to avoid parse errors):
1. Use 'graph {graph_direction}' for {'top-down' if style == 'TD' else 'left-right'} layout
2. Node IDs: Use only [A-Z][A-Z0-9]* (e.g., A, B1, C2, ROOT)
3. Node labels: Wrap in square brackets [Label Text]
4. Connections: Use --> between nodes (e.g., A --> B1)

LABEL TEXT SAFETY RULES (CRITICAL - most common source of parse errors):
**FORBIDDEN CHARACTERS in labels:**
- NO parentheses: ( )  - causes "Expecting 'SQE', got 'PS'" error
- NO square brackets: [ ]  - conflicts with label delimiters
- NO curly braces: {{ }}  - conflicts with special nodes
- NO angle brackets: < >  - reserved syntax
- NO pipes: |  - reserved for subgraphs
- NO quotes: " '  - can break string parsing
- NO backslashes: \  - escape character issues
- NO special math symbols: Ï€, Â², Â³, Î±, Î², Î³, Î¸, Ï†, Ï‰, Î”, âˆ‘, âˆ«, âˆš, âˆ
- NO math operators in complex expressions: ^, ~, â‰ˆ, â‰ , â‰¤, â‰¥, Â±, Ã—, Ã·
- NO semicolons or colons in complex contexts: ; :

**SAFE ALTERNATIVES:**
- Mathematical expressions:
  * "z = r e^(i theta)" â†’ "z equals r times exponential of i theta"
  * "f(x) = xÂ²" â†’ "f of x equals x squared"
  * "âˆ« f(x) dx" â†’ "integral of f x dx"
  * "Î£(n=1 to âˆ)" â†’ "sum from n equals 1 to infinity"
  * "Î¸â‚€ + 2kÏ€" â†’ "theta-0 plus 2k pi"
  
- Use descriptive phrases:
  * Instead of "f(x)", use "function f of x" or "f-x"
  * Instead of "(a+b)Â²", use "a plus b squared"
  * Instead of "cos(Î¸)", use "cosine theta" or "cos-theta"
  
- For technical terms, use hyphens or underscores:
  * "euler_formula" instead of "Euler's formula (e^iÎ¸)"
  * "complex-form" instead of "(a + bi)"
  * "nth-term" instead of "n-th term"

**SAFE CHARACTERS:**
- Letters: a-z, A-Z
- Numbers: 0-9
- Basic punctuation: . , ! ? (use sparingly)
- Separators: space, hyphen -, underscore _
- Safe operators in simple context: + - * / =

6. Format rules:
   - Each line: one node definition OR one connection
   - Node definition: NodeID[Label]
   - Connection: NodeID --> NodeID
   - No inline comments or extra text

7. Structure:
   - Define ALL nodes first (one per line)
   - Then define ALL connections (one per line)
   - OR define node and its connections together

EXAMPLE of CORRECT syntax:
graph {graph_direction}
    A[Central Topic]
    B1[Branch One]
    B2[Branch Two]
    C1[Detail 1]
    C2[Detail 2]
    A --> B1
    A --> B2
    B1 --> C1
    B1 --> C2

EXAMPLE with math content (SAFE):
graph {graph_direction}
    A[Complex Numbers]
    B1[Polar Form]
    B2[Exponential Form]
    C1[r times cosine theta plus i sine theta]
    C2[r times e to the i theta]
    A --> B1
    A --> B2
    B1 --> C1
    B2 --> C2

Rules for HIERARCHICAL style:
- Clear parent-child relationships
- Logical hierarchical structure
- Keep labels simple and readable
- Only output the Mermaid code, no explanations or markdown blocks"""

        # å¤„ç†depthå‚æ•°
        if depth == 'auto' or depth == 'auto':
            depth_instruction = "Automatically determine the appropriate depth based on the topic complexity (typically 3-5 levels)"
        else:
            try:
                depth = int(depth)
                depth_instruction = f"Create exactly {depth} levels of hierarchy"
            except:
                depth = 3
                depth_instruction = "Create 3 levels of hierarchy"

        if style == 'radial':
            user_prompt = f"""Generate a RADIAL mind map using Mermaid's mindmap syntax for: "{topic}"

Style: Radial mindmap (refer to hierarchy style for similar visual appearance)
Depth: {depth_instruction}
{f'Additional context: {context}' if context else ''}

STRICT REQUIREMENTS:
- Use 'mindmap' syntax
- Root node: root(({topic}))
- Create 5-8 main branches from root
- Use alternating shapes for level 1: (Branch1), [Branch2], (Branch3), [Branch4], etc.
- Each main branch: 2-4 child items
- Each child item: 0-2 sub-items (if depth allows)
- CRITICAL: Use exactly 2 spaces for each indentation level
- Keep siblings at EXACT same indentation
- Balance branch sizes (similar number of children)
- Use concise labels (3-8 words max)

LABEL SAFETY (MOST IMPORTANT):
- NO parentheses ( ), brackets [ ], braces {{ }} in any label text
- NO mathematical symbols: Ï€, Â², Â³, Î±, Î², Î³, Î¸, etc.
- For equations, use plain English: "x squared" not "xÂ²", "theta" not "Î¸"
- Simple, clear, descriptive text only

EXAMPLE STRUCTURE:
mindmap
  root(({topic}))
    (Category A)
      Detail A1
      Detail A2
        Sub A2.1
    [Category B]
      Detail B1
      Detail B2
      Detail B3
    (Category C)
      Detail C1
      Detail C2

OUTPUT: Only the mindmap code, starting with 'mindmap'"""
        else:
            user_prompt = f"""Generate a HIERARCHICAL mind map in Mermaid syntax for: "{topic}"

Style: {'Top-Down' if style == 'TD' else 'Left-Right'} hierarchy
Depth: {depth_instruction}
{f'Additional context: {context}' if context else ''}

CRITICAL REQUIREMENTS to avoid syntax errors:
1. Start with 'graph {style}'
2. Node IDs: Simple alphanumeric only (A, B1, C2, ROOT, NODE1, etc.)
3. Labels in [square brackets]: Follow SAFETY RULES below

**LABEL SAFETY RULES (CRITICAL):**
- NEVER use parentheses ( ) - causes immediate parse error
- NEVER use square brackets [ ] - conflicts with label syntax
- NEVER use curly braces {{ }} - conflicts with special nodes
- NO mathematical symbols at all: Ï€ Â² Â³ Î± Î² Î³ Î¸ Ï† Ï‰ Î” âˆ‘ âˆ« âˆš âˆ
- NO complex punctuation: < > | & ~ ^ ` quotes

**For mathematical/technical content:**
- Use plain text descriptions
- Example: "z = re^i(theta0 + 2kpi)" â†’ "z equals r e to the i theta"
- Example: "f(x) = xÂ²" â†’ "function f-x equals x squared"
- Example: "cos(Î¸)" â†’ "cosine of theta" or "cos-theta"
- Use hyphens/underscores for compound terms: "euler-formula", "complex_number"

4. Structure:
   - Define nodes first: A[Label Text]
   - Then connections: A --> B
   - Clear hierarchy from general to specific
   
5. Keep labels concise (3-8 words) and readable
6. Each branch: 2-4 sub-nodes where appropriate

EXAMPLE FORMAT:
graph {style}
    ROOT[{topic}]
    A[Main Concept 1]
    B[Main Concept 2]
    ROOT --> A
    ROOT --> B
    A1[Detail 1.1]
    A2[Detail 1.2]
    A --> A1
    A --> A2

EXAMPLE with technical content:
graph {style}
    A[Complex Numbers]
    B[Polar Representation]
    C[r times e to the i theta]
    D[Euler Formula Connection]
    A --> B
    B --> C
    B --> D

OUTPUT: Only valid Mermaid code, no markdown blocks, no explanations"""

        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                stream=False,
                temperature=1.0,
                max_tokens=2000
            )
            
            mermaid_code = response.choices[0].message.content.strip()
            
            # æ¸…ç†ä»£ç å—æ ‡è®°
            if mermaid_code.startswith('```mermaid'):
                mermaid_code = mermaid_code.replace('```mermaid', '').replace('```', '').strip()
            elif mermaid_code.startswith('```'):
                mermaid_code = mermaid_code.replace('```', '').strip()
            
            return mermaid_code
            
        except Exception as e:
            print(f"Error calling DeepSeek API: {e}")
            return self._generate_fallback_mindmap(topic, depth, style)
    
    def generate_mindmap_from_content(self, topic, file_content, depth=3, style='TD'):
        """
        æ ¹æ®æ–‡ä»¶å†…å®¹ç”Ÿæˆæ€ç»´å¯¼å›¾
        """
        if style == 'radial':
            system_prompt = """You are a mind map generation assistant. Analyze content and create a RADIAL mind map using Mermaid's mindmap syntax.

Follow official Mermaid mindmap specification:
- Use 'mindmap' keyword
- Root: root((text)) with circle shape
- Level 1: Use (text) or [text] shapes alternately
- Exactly 2 spaces per indentation level
- Siblings at exact same indentation
- Balance branches (similar number of children)

LABEL SAFETY (CRITICAL):
- NO parentheses ( ), brackets [ ], braces {{ }} in label text
- NO mathematical symbols: Ï€, Â², Â³, Î±, Î², Î³, Î¸, etc.
- NO operators that could conflict: <, >, |, &, ^
- Use plain English/Chinese descriptions for technical terms
- For equations: "x squared" not "xÂ²", "pi" not "Ï€", "theta" not "Î¸"

Focus on extracting key concepts and organizing them hierarchically."""
        else:
            graph_direction = 'TD' if style == 'TD' else 'LR'
            system_prompt = f"""You are a mind map generation assistant. Analyze the provided content and create a HIERARCHICAL mind map in Mermaid syntax using 'graph {graph_direction}'.

CRITICAL SYNTAX RULES to prevent parse errors:
1. Node IDs: Simple alphanumeric (A, B1, C2, ROOT)
2. Labels: Plain text only in [brackets]
3. Format: Define nodes, then connections
4. One statement per line

LABEL SAFETY RULES (MOST IMPORTANT):
**NEVER use these characters in labels:**
- Parentheses: ( )  - causes "Expecting 'SQE', got 'PS'" error
- Brackets: [ ]  - conflicts with label delimiters
- Braces: {{ }}  - conflicts with special syntax
- Math symbols: Ï€, Â², Â³, Î±, Î², Î³, Î¸, Ï†, Ï‰, Î”, âˆ‘, âˆ«, âˆš, âˆ
- Operators: < > | & ~ ^ (except in simple contexts)
- Quotes: " '

**Use safe alternatives:**
- "f(x) = xÂ²" â†’ "function f-x equals x squared"
- "e^(iÎ¸)" â†’ "e to the i theta"
- "âˆ« f(x) dx" â†’ "integral of f-x dx"
- "(a+b)Â²" â†’ "a plus b squared"
- "Î¸â‚€" â†’ "theta-0"

Focus on extracting key concepts, relationships, and hierarchies from the content."""

        # å¤„ç†depthå‚æ•°
        if depth == 'auto' or depth == 'auto':
            depth_instruction = "Automatically determine the appropriate depth based on content complexity and richness"
        else:
            try:
                depth = int(depth)
                depth_instruction = f"Create exactly {depth} levels of hierarchy"
            except:
                depth = 3
                depth_instruction = "Create 3 levels of hierarchy"

        if style == 'radial':
            user_prompt = f"""Create a mind map using Mermaid's mindmap syntax for: "{topic}"

Based on this content:
{file_content[:2000]}

Style: Radial mindmap (refer to hierarchy for similar appearance)
Depth: {depth_instruction}

REQUIREMENTS:
- Extract main concepts from content
- Organize in mindmap structure: root((Topic))
- Use alternating shapes for level 1: (Branch), [Branch]
- Exactly 2 spaces per indentation
- 5-8 main branches with 2-4 children each
- Balance branch sizes

CRITICAL LABEL SAFETY:
- NO parentheses, brackets, or braces in any label
- NO mathematical symbols (Ï€, Â², Â³, Î¸, Î±, etc.)
- Use plain descriptive text only
- For technical terms: use simple English/Chinese

OUTPUT: Only mindmap code, no markdown blocks"""
        else:
            user_prompt = f"""Create a mind map in Mermaid syntax for: "{topic}"

Based on this content:
{file_content[:2000]}

Style: {'Top-Down' if style == 'TD' else 'Left-Right'} hierarchy
Depth: {depth_instruction}

CRITICAL SYNTAX REQUIREMENTS:
- Start with 'graph {style}'
- Node IDs: Alphanumeric only (ROOT, A, B1, C2)
- Labels in [brackets]: Follow SAFETY rules

**LABEL SAFETY (MOST CRITICAL):**
- NEVER use parentheses ( ) in labels - causes parse error
- NEVER use brackets [ ] or braces {{ }} in labels
- NO math symbols: Ï€, Â², Â³, Î±, Î², Î³, Î¸, etc.
- Use plain text alternatives:
  * "e^(iÎ¸)" â†’ "e to the i theta"
  * "f(x)" â†’ "function f-x" or "f of x"
  * "xÂ²" â†’ "x squared"
  * Use hyphens for compound terms: "euler-formula"

- Define nodes, then connections
- Clear hierarchy structure
- Extract main ideas and organize {'top-down' if style == 'TD' else 'left-right'}

OUTPUT: Only valid Mermaid code, no markdown, no explanations"""

        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                stream=False,
                temperature=1.0,
                max_tokens=2000
            )
            
            mermaid_code = response.choices[0].message.content.strip()
            
            # æ¸…ç†ä»£ç å—æ ‡è®°
            if mermaid_code.startswith('```mermaid'):
                mermaid_code = mermaid_code.replace('```mermaid', '').replace('```', '').strip()
            elif mermaid_code.startswith('```'):
                mermaid_code = mermaid_code.replace('```', '').strip()
            
            return mermaid_code
            
        except Exception as e:
            print(f"Error calling DeepSeek API: {e}")
            return self._generate_fallback_mindmap(topic, depth, style)
    
    def _generate_fallback_mindmap(self, topic, depth, style='TD'):
        """åå¤‡æ–¹æ¡ˆï¼šç”ŸæˆåŸºç¡€æ€ç»´å¯¼å›¾"""
        if style == 'radial':
            # ä½¿ç”¨åŸç”Ÿ mindmap è¯­æ³•ï¼Œäº¤æ›¿ä½¿ç”¨å½¢çŠ¶
            mermaid_code = f"""mindmap
  root(({topic}))
    (Core Concept 1)
      Key Point 1.1
      Key Point 1.2
      Key Point 1.3
    [Core Concept 2]
      Key Point 2.1
      Key Point 2.2
    (Core Concept 3)
      Key Point 3.1
      Key Point 3.2
      Key Point 3.3
    [Core Concept 4]
      Key Point 4.1
      Key Point 4.2
    (Core Concept 5)
      Key Point 5.1
      Key Point 5.2"""
            
            if depth >= 3:
                mermaid_code += """
        Detail 1.1.1
        Detail 1.1.2
        Detail 2.1.1"""
        else:
            # å±‚çº§å‹æ€ç»´å¯¼å›¾
            graph_dir = 'TD' if style == 'TD' else 'LR'
            mermaid_code = f"""graph {graph_dir}
    A[{topic}]
    """
            
            if depth >= 1:
                mermaid_code += """    A --> B1[Core Concept 1]
    A --> B2[Core Concept 2]
    A --> B3[Core Concept 3]
    """
            
            if depth >= 2:
                mermaid_code += """    B1 --> C1[Detail 1.1]
    B1 --> C2[Detail 1.2]
    B2 --> C3[Detail 2.1]
    B2 --> C4[Detail 2.2]
    B3 --> C5[Detail 3.1]
    """
            
            if depth >= 3:
                mermaid_code += """    C1 --> D1[Example 1.1.1]
    C2 --> D2[Example 1.2.1]
    C3 --> D3[Example 2.1.1]
    """
        
        return mermaid_code.strip()
    
    
    
    
    
    
    
    
    
    
    def chat(self, user_message, conversation_history=None):
        """
        å¤„ç†èŠå¤©å¯¹è¯
        user_message: ç”¨æˆ·æ¶ˆæ¯
        conversation_history: å†å²å¯¹è¯åˆ—è¡¨ï¼Œæ ¼å¼ [{'role': 'user/assistant', 'content': '...'}]
        
        Temperatureè®¾ç½®è¯´æ˜(å®˜æ–¹æ¨è):
        - General Conversation: 1.3 (é€šç”¨å¯¹è¯,éœ€è¦æ›´è‡ªç„¶å’Œå¤šæ ·åŒ–çš„å›å¤)
        - Coding/Math: 0.0 (ä»£ç å’Œæ•°å­¦éœ€è¦ç²¾ç¡®æ€§)
        - Data Cleaning/Analysis: 1.0 (æ•°æ®åˆ†æéœ€è¦å¹³è¡¡å‡†ç¡®æ€§å’Œçµæ´»æ€§)
        """
        if conversation_history is None:
            conversation_history = []
        
        system_prompt = """You are a helpful AI study assistant. You help students with:
- Answering questions about their studies
- Explaining concepts clearly
- Providing learning guidance
- Helping with homework and assignments
- Organizing study materials

Be friendly, clear, and concise in your responses. Use LaTeX notation for mathematical formulas (e.g., $x^2$ for inline math, $$\\frac{a}{b}$$ for display math). Format your answers well for readability."""
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [{"role": "system", "content": system_prompt}]
        
        # æ·»åŠ å†å²å¯¹è¯ï¼ˆæœ€å¤šä¿ç•™æœ€è¿‘10è½®å¯¹è¯ä»¥æ§åˆ¶tokenå’Œé€Ÿåº¦ï¼‰
        if conversation_history:
            recent_history = conversation_history[-10:] if len(conversation_history) > 10 else conversation_history
            messages.extend(recent_history)
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                stream=False,
                temperature=1.3,  # é€šç”¨å¯¹è¯æ¨èå€¼,æä¾›æ›´è‡ªç„¶å’Œå¤šæ ·åŒ–çš„å›å¤
                max_tokens=500
            )
            
            ai_response = response.choices[0].message.content.strip()
            return ai_response
            
        except Exception as e:
            print(f"Error calling DeepSeek chat API: {e}")
            raise Exception("Failed to get AI response")
    
    def generate_similar_questions(self, question_text, count=3, grade=None):
        """
        ç”Ÿæˆç›¸ä¼¼ç»ƒä¹ é¢˜
        
        Args:
            question_text: åŸé¢˜æ–‡æœ¬
            count: ç”Ÿæˆé¢˜ç›®æ•°é‡
            grade: å­¦ç”Ÿå¹´çº§ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚ "Grade 7", "Grade 10" ç­‰
            
        Returns:
            list: ç›¸ä¼¼é¢˜ç›®åˆ—è¡¨ï¼Œæ¯ä¸ªé¢˜ç›®åŒ…å« question_text, correct_answer, subject, type, tags, analysis_steps
        """
        grade_info = f"\n- **å­¦ç”Ÿå¹´çº§**: {grade}ï¼Œè¯·ç¡®ä¿é¢˜ç›®éš¾åº¦é€‚åˆè¯¥å¹´çº§æ°´å¹³" if grade else ""
        
        prompt = f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­å­¦æ•™å¸ˆï¼Œä»»åŠ¡æ˜¯æ ¹æ®ä»¥ä¸‹åŸé¢˜ç”Ÿæˆ {{count}} é“"ç›¸ä¼¼çŸ¥è¯†ç‚¹ã€ç›¸ä¼¼éš¾åº¦"çš„ç›¸ä¼¼ç»ƒä¹ é¢˜ï¼Œå¹¶ä¸ºæ¯é“é¢˜æä¾›æ ‡å‡†ç­”æ¡ˆã€‚
{grade_info}

âš ï¸ ä¸¥æ ¼è¦æ±‚ï¼š
- é¢˜ç›®å¿…é¡»ç›¸ä¼¼ä½†ä¸é‡å¤ï¼ˆæ”¹å˜æ•°å­—ã€æƒ…å¢ƒã€è¡¨è¾¾æ–¹å¼ã€æ±‚è§£å†…å®¹ï¼‰
- ä¿æŒç›¸ä¼¼é¢˜å‹ã€ç§‘ç›®ã€çŸ¥è¯†ç‚¹
- æ¯é“é¢˜åŒ…å«ï¼šé¢˜ç›®ï¼ˆquestion_textï¼‰å’Œæ ‡å‡†ç­”æ¡ˆï¼ˆcorrect_answerï¼‰ï¼Œç§‘ç›®ï¼Œé¢˜ç›®ç±»å‹ï¼ŒçŸ¥è¯†ç‚¹ï¼Œåˆ†ææ­¥éª¤
- ç§‘ç›®ï¼ˆsubjectï¼‰ä» Chinese, Mathematics, English, Physics, Chemistry, Politics, History, Geography, Biology ä¸­é€‰æ‹©ã€‚
- ä¸è¦å‡ºæœ‰å›¾ç‰‡çš„é¢˜ç›®
- åªè¾“å‡ºä¸€ä¸ª JSON æ•°ç»„ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€æ³¨é‡Šæˆ– Markdown
- æ•°ç»„é•¿åº¦å¿…é¡»ç­‰äº {{count}}
- subjectï¼Œtypeï¼Œtagsç”¨è‹±è¯­
- **åŸé¢˜é¢˜ç›®æ˜¯è‹±è¯­çš„å°±å…¨éƒ¨ç”¨è‹±è¯­**
- **è¾“å‡ºçš„ JSON å¿…é¡»æ˜¯ä¸¥æ ¼åˆæ³•çš„ï¼Œæ‰€æœ‰åæ–œæ å¿…é¡»åŒå†™ï¼ˆå¦‚ \\\\fracï¼‰ï¼Œç¡®ä¿èƒ½è¢« Python json.loads ç›´æ¥è§£æã€‚**

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
[
  {{
    "subject": "Mathematics",
    "type": "Single choice",
    "tags": ["Quadratic Equation", "Discriminant"],
    "question_text": "é¢˜ç›®åŸæ–‡",
    "analysis_steps": ["æ­¥éª¤1", "æ­¥éª¤2"],
    "correct_answer": "æ ‡å‡†ç­”æ¡ˆ"
  }}
]

åŸé¢˜å¦‚ä¸‹ï¼š
=====================
{question_text}
=====================
"""
        
        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                stream=False,
                temperature=0.3,  # æ•°å­¦/ä»£ç ç±»ä»»åŠ¡éœ€è¦ç²¾ç¡®æ€§
                max_tokens=8000,
                response_format={"type": "json_object"}
            )
            
            raw_output = response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„ Markdown ä»£ç å—
            if raw_output.startswith('```json'):
                raw_output = raw_output.replace('```json', '').replace('```', '').strip()
            elif raw_output.startswith('```'):
                raw_output = raw_output.replace('```', '').strip()
            
            # æå– JSON å¯¹è±¡
            import re
            start = raw_output.find('[')
            end = raw_output.rfind(']')
            if start != -1 and end > start:
                json_str = raw_output[start:end + 1]
            else:
                raise ValueError("No valid JSON array found in response")
            
            import json
            similar_list = json.loads(json_str)
            
            # è¡¥é½æˆ–æˆªæ–­åˆ°æŒ‡å®šæ•°é‡
            similar_list = similar_list[:count]
            while len(similar_list) < count:
                similar_list.append({
                    "question_text": "ï¼ˆç”Ÿæˆå¤±è´¥ï¼‰",
                    "correct_answer": "",
                    "subject": "",
                    "type": "",
                    "tags": [],
                    "analysis_steps": []
                })
            
            return similar_list
            
        except Exception as e:
            print(f"Error generating similar questions: {e}")
            raise Exception(f"Failed to generate similar questions: {str(e)}")
    
    def judge_text_answer(self, question_text, user_answer, correct_answer=None):
        """
        åˆ¤æ–­æ–‡æœ¬ç­”æ¡ˆæ˜¯å¦æ­£ç¡®
        
        Args:
            question_text: é¢˜ç›®æ–‡æœ¬
            user_answer: ç”¨æˆ·ç­”æ¡ˆ
            correct_answer: æ ‡å‡†ç­”æ¡ˆï¼ˆå¯é€‰ï¼‰
            
        Returns:
            dict: {'is_correct': bool, 'reason': str}
        """
        prompt = f"""
You are a strict middle school teacher. Please judge whether the student's answer is correct.

Question:
{question_text}

'Standard Answer:
{correct_answer}

Accept simplified answers, such as numerical values or option letters.
Accept numerical answers without units; slightly imprecise but correct final answers are acceptable.

[Requirements]
1. First, solve the problem completely by yourself to obtain the correct answer.
2. Compare the student's answer with the correct answer, and use "is_correct" to indicate whether it is correct.
3. Output only pure JSON:
{{
    "reason": "Give me the step-by-step derivation process of the correct answer, one point per line",
    "is_correct": true or false
}}

Student's submitted answer:
{user_answer}
=====================
"""
        
        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                stream=False,
                temperature=0.0,  # åˆ¤åˆ†éœ€è¦ç²¾ç¡®æ€§
                max_tokens=1000
            )
            
            raw_output = response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„ Markdown åŒ…è£¹
            if raw_output.startswith("```json"):
                raw_output = raw_output.split("```json", 1)[1].split("```", 1)[0]
            elif raw_output.startswith("```"):
                raw_output = raw_output.split("```", 1)[1].split("```", 1)[0]
            
            import json
            parsed = json.loads(raw_output.strip())
            
            
            return {
                'is_correct': bool(parsed.get("is_correct", False)),
                'reason': str(parsed.get("reason", "")).strip()
            }
            
        except Exception as e:
            print(f"Error judging answer: {e}")
            return {
                'is_correct': False,
                'reason': "AI åˆ¤å®šå¤±è´¥ï¼Œé»˜è®¤åˆ¤é”™"
            }

    def _clean_json_for_object(self, text: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå– JSONï¼ˆå¯¹è±¡æˆ–æ•°ç»„ï¼‰ï¼Œå¹¶ä¿®å¤ LaTeX å¯¼è‡´çš„éæ³•è½¬ä¹‰"""
        text = text.strip()
        text = re.sub(r'^```(?:json)?\s*', '', text)
        text = re.sub(r'\s*```$', '', text)

        # å°è¯•æå–æ•°ç»„
        start = text.find('[')
        end = text.rfind(']')
        if start != -1 and end > start:
            extracted = text[start:end + 1]
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå°†æ‰€æœ‰ \ è½¬ä¹‰ä¸º \\ï¼Œä½¿ JSON åˆæ³•
            return extracted.replace('\\', '\\\\')

        # å°è¯•æå–å¯¹è±¡
        start = text.find('{')
        end = text.rfind('}')
        if start != -1 and end > start:
            extracted = text[start:end + 1]
            # ğŸ”¥ åŒæ ·ä¿®å¤
            return extracted.replace('\\', '\\\\')

        raise ValueError("No valid JSON found")

    def ocr_and_parse_question(self, orig_path, cropped_results):
        """
        ä½¿ç”¨ Qwen-VL è¯†åˆ«é¢˜ç›®å›¾ç‰‡å¹¶è§£æ
        
        Args:
            orig_path: åŸå§‹å›¾ç‰‡è·¯å¾„
            cropped_results: è£å‰ªå›¾ç‰‡ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« abs_path, bbox ç­‰ä¿¡æ¯
            
        Returns:
            è§£æåçš„é¢˜ç›®åˆ—è¡¨ï¼ˆå·²å¤„ç† JSONï¼‰
        """
        # æ„å»º prompt
        prompt = (
            "ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„ä¸­å­¦æ•™å¸ˆï¼Œè¯·æ ¹æ®ç¬¬ä¸€å¼ å›¾ç‰‡è¯†åˆ«é¢˜ç›®å†…å®¹ã€ç­”æ¡ˆå’Œè§£æã€‚\n"
            "ã€å›¾åƒè¯´æ˜ã€‘\n"
            "- å›¾åƒ0ï¼šå®Œæ•´åŸé¢˜å›¾ç‰‡ï¼ˆåŒ…å«é¢˜å¹²ã€é€‰é¡¹ã€ç­”æ¡ˆç­‰å…¨éƒ¨å†…å®¹ï¼‰\n"
            "- å›¾åƒ1, 2, 3, ...ï¼šç³»ç»Ÿè‡ªåŠ¨è£å‰ªçš„å±€éƒ¨å›¾ï¼ˆå¦‚é€‰é¡¹å›¾ã€å®éªŒå›¾ã€åæ ‡ç³»ç­‰ï¼‰\n"
            "- æ³¨æ„ï¼š**è£å‰ªå›¾çš„ç´¢å¼•ä» 0 å¼€å§‹**ï¼Œå³ï¼š\n"
            "    â€¢ å›¾åƒ1 â†’ è£å‰ªå›¾ç´¢å¼• 0\n"
            "    â€¢ å›¾åƒ2 â†’ è£å‰ªå›¾ç´¢å¼• 1\n"
            "    â€¢ å›¾åƒ3 â†’ è£å‰ªå›¾ç´¢å¼• 2\n"
            "    â€¢ ä»¥æ­¤ç±»æ¨\n"
            "\n"
            "**å…³é”®ï¼šä¸ºæ¯é“é¢˜æŒ‡å®šå®ƒæ‰€ä¾èµ–çš„è£å‰ªå›¾ç´¢å¼•ï¼ˆcrop_indexï¼‰**\n"
            "   - crop_index æ˜¯ä¸€ä¸ªæ•´æ•°åˆ—è¡¨ï¼Œä¾‹å¦‚ [0], [1,2], [0,1,2,3,4,5] æˆ– []ã€‚\n"
            "   - **å¦‚æœæ•´å¼ åŸå›¾åªåŒ…å«ä¸€é“é¢˜ï¼ˆæ— è®ºå¤šå°‘å°é—®ï¼‰ï¼Œåˆ™è¯¥é¢˜å¿…é¡»åŒ…å«æ‰€æœ‰è£å‰ªå›¾ç´¢å¼•ã€‚**\n"
            "   - ä»…å½“åŸå›¾æ˜ç¡®åŒ…å«å¤šé“ç‹¬ç«‹é¢˜ç›®æ—¶ï¼Œæ‰å¯å°†è£å‰ªå›¾åˆ†é…ç»™ä¸åŒé¢˜ã€‚\n"
            "   - ä¸€é“è£å‰ªå›¾åªèƒ½å±äºä¸€é“é¢˜ã€‚\n"
            "\n"
            "1. 'question_text' å¿…é¡»å®Œæ•´åŒ…å«é¢˜ç›®åŸæ–‡åŠæ‰€æœ‰é€‰é¡¹ã€‚\n"
            "2. åªè¾“å‡ºåˆæ³• JSON æ•°ç»„ï¼Œä¸è¦è§£é‡Šã€Markdown æˆ–é¢å¤–æ–‡å­—ã€‚\n"
            "è¯·ä¸¥æ ¼è¾“å‡º JSON æ•°ç»„ï¼Œåªå…è®¸ä½¿ç”¨ä»¥ä¸‹è½¬ä¹‰ï¼š \\\\, \\\", \\n, \\t, \\r,æ‰€æœ‰ LaTeX å…¬å¼ä¸­çš„åæ–œæ å¿…é¡»ä½¿ç”¨åŒåæ–œæ  \\\\ï¼Œä¸è¦ç”Ÿæˆå•åæ–œæ ã€‚"
            "3. ç§‘ç›®ï¼ˆsubjectï¼‰ä» Chinese, Mathematics, English, Physics, Chemistry, Politics, History, Geography, Biology ä¸­é€‰æ‹©ã€‚\n"
            "4. é¢˜å‹ï¼ˆtypeï¼‰ã€çŸ¥è¯†ç‚¹ï¼ˆtagsï¼‰ä½¿ç”¨è‹±æ–‡æè¿°ã€‚\n"
            "5. 'correct_answer' å’Œ 'analysis_steps' å¿…é¡»åŸºäºé¢˜ç›®æ¨å¯¼ï¼Œä¸ç”¨æˆ·ç­”æ¡ˆæ— å…³ã€‚\n"
            "6. 'user_answer' ä¸ºå›¾ç‰‡ä¸Šçš„ç­”æ¡ˆã€‚\n"
            "è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºç¤ºä¾‹ï¼š\n"
            "[\n"
            "  {\n"
            "    \"subject\": \"Chinese\",\n"
            "    \"type\": \"Constructed-response question\",\n"
            "    \"tags\": [\"Trigonometric Functions\",\"Induction Formulas\"],\n"
            "    \"question_text\": \"é¢˜ç›®åŸæ–‡\",\n"
            "    \"analysis_steps\": [\"æ­£ç¡®æ­¥éª¤1\",\"æ­£ç¡®æ­¥éª¤2\"],\n"
            "    \"correct_answer\": \"æ­£ç¡®ç­”æ¡ˆ\",\n"
            "    \"user_answer\": \"å­¦ç”Ÿç­”æ¡ˆ\",\n"
            "    \"crop_index\": []\n"
            "  },\n"
            "  {... ç¬¬äºŒé¢˜ ...}\n"
            "]"
        )

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = [{
            "role": "user",
            "content": (
                [{"image": f"file://{os.path.abspath(orig_path)}"}] +
                [{"image": f"file://{crop['abs_path']}"} for crop in cropped_results] +
                [{"text": prompt}]
            )
        }]

        # è°ƒç”¨ Qwen-VL
        response = MultiModalConversation.call(
            model='qwen-vl-plus',
            messages=messages,
            api_key=self.dashscope_api_key,
            result_format='message'
        )

        if response.status_code != 200:
            raise Exception(f"Qwen-VL API Error {response.code}: {response.message}")

        raw_output = response.output.choices[0].message.content[0]['text']
        print("=== CLEANED JSON (repr) ===")
        print(repr(raw_output))
        print("=== END ===")

        cleaned_json = self._clean_json_for_object(raw_output)

        try:
            parsed_list = json.loads(cleaned_json)
        except json.JSONDecodeError as e:
            print("JSON è§£æå¤±è´¥ï¼Œå¯åŠ¨ä¿®å¤æ¨¡å¼â€¦")
            print(e)

            repaired = cleaned_json
            # å°è¯•äºŒæ¬¡ä¿®å¤ï¼šå»æ‰å­¤ç«‹åæ–œæ 
            repaired = repaired.replace("\\'", "'")
            repaired = repaired.replace('\\"', '"')

            # å†è¯•
            parsed_list = json.loads(repaired)

        if not isinstance(parsed_list, list):
            raise ValueError("æ¨¡å‹è¿”å›çš„ä¸æ˜¯ JSON æ•°ç»„ï¼Œè¯·æ£€æŸ¥è¾“å‡ºæ ¼å¼ã€‚")

        return parsed_list

    def judge_redo_answer_with_image(self, question_text, correct_answer, image_path):
        """
        ä½¿ç”¨ Qwen-VL åˆ¤æ–­é‡åšç­”æ¡ˆï¼ˆå›¾ç‰‡å½¢å¼ï¼‰
        
        Args:
            question_text: é¢˜ç›®æ–‡æœ¬
            correct_answer: æ­£ç¡®ç­”æ¡ˆ
            image_path: ç”¨æˆ·ç­”æ¡ˆå›¾ç‰‡è·¯å¾„
            
        Returns:
            dict: {'user_answer': str, 'is_correct': bool}
        """
        prompt = f"""
å·²çŸ¥é¢˜ç›®å¦‚ä¸‹ï¼ˆæ–‡å­—å½¢å¼æä¾›ï¼Œä¸éœ€è¦è¯†åˆ«å›¾ç‰‡ä¸­çš„é¢˜ç›®ï¼‰ï¼š
{question_text}

è¯·ä¸¥æ ¼å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. **ä»…è¯†åˆ«ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡ä¸­çš„ç­”æ¡ˆéƒ¨åˆ†**ï¼ˆä¸è¦åŒ…å«é¢˜ç›®ã€è§£æã€è‰ç¨¿ç­‰ï¼‰ã€‚
2. **åˆ¤æ–­è¯¥ç­”æ¡ˆæ˜¯å¦ä¸ä¸Šè¿°é¢˜ç›®çš„å­¦ç§‘å’Œå†…å®¹ç›¸å…³**ï¼š
   - å¦‚æœé¢˜ç›®æ˜¯ç”Ÿç‰©/åŒ–å­¦/å†å²ç­‰éæ•°å­¦é¢˜ï¼Œä½†ç­”æ¡ˆåŒ…å«å¤§é‡æ•°å­¦å…¬å¼ã€æ–¹ç¨‹ã€ç¬¦å·ï¼ˆå¦‚ x=, âˆ«, âˆ‘, Î” ç­‰ï¼‰ï¼Œè§†ä¸º**æ— æ•ˆç­”æ¡ˆ**ï¼Œåˆ¤é”™ã€‚
   - å¦‚æœç­”æ¡ˆæ˜æ˜¾ä¸é¢˜ç›®ä¸»é¢˜æ— å…³ï¼ˆå¦‚é¢˜ç›®é—®ç»†èƒç»“æ„ï¼Œç­”æ¡ˆå†™"E=mcÂ²"ï¼‰ï¼Œåˆ¤é”™ã€‚
3. **ä»…å½“å›¾ç‰‡ä¸­ç­”æ¡ˆå†…å®¹åˆç†ä¸”ä¸é¢˜ç›®åŒ¹é…æ—¶**ï¼Œæ‰è¿›è¡Œæ­£ç¡®æ€§åˆ¤æ–­ã€‚
4. è¾“å‡ºå¿…é¡»æ˜¯ä¸¥æ ¼ JSON æ ¼å¼ï¼Œä¸è¦ä»»ä½•é¢å¤–æ–‡å­—ã€‚

è¾“å‡ºæ ¼å¼ï¼š
{{
  "user_answer": "è¯†åˆ«å‡ºçš„å›¾ç‰‡ä¸­çš„ç­”æ¡ˆåŸæ–‡ï¼Œä¸æ˜¯åŸé¢˜ç›®çš„ç­”æ¡ˆï¼ˆä¿ç•™åŸå§‹æ ¼å¼ï¼ŒåŒ…æ‹¬ LaTeXï¼‰",
  "is_correct": true æˆ– false
}}
"""

        messages = [{
            "role": "user",
            "content": [
                {"image": f"file://{os.path.abspath(image_path)}"},
                {"text": prompt}
            ]
        }]

        response = MultiModalConversation.call(
            model='qwen-vl-plus',
            messages=messages,
            api_key=self.dashscope_api_key,
            result_format='message'
        )

        raw_output = response.output.choices[0].message.content[0]['text']
        

        parsed = json.loads(self._clean_json_for_object(raw_output))
        
        
        return {
            'user_answer': parsed.get("user_answer", "").strip(),
            'is_correct': parsed.get("is_correct", False)
        }

    def judge_practice_answer_with_image(self, question_text, correct_answer, image_path):
        """
        ä½¿ç”¨ Qwen-VL åˆ¤æ–­ç»ƒä¹ ç­”æ¡ˆï¼ˆå›¾ç‰‡å½¢å¼ï¼‰
        
        Args:
            question_text: é¢˜ç›®æ–‡æœ¬
            correct_answer: æ­£ç¡®ç­”æ¡ˆ
            image_path: ç”¨æˆ·ç­”æ¡ˆå›¾ç‰‡è·¯å¾„
            
        Returns:
            dict: {'user_answer': str, 'is_correct': bool}
        """
        prompt = f"""
å·²çŸ¥é¢˜ç›®å¦‚ä¸‹ï¼š
{question_text}

è¯·è‡ªå·±åšä¸€æ¬¡é¢˜ç›®ï¼Œç»™å‡ºå¯¹åº”çš„è¿‡ç¨‹å’Œç­”æ¡ˆï¼Œç„¶åè¯†åˆ«ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡ä¸­çš„ç­”æ¡ˆï¼Œå¹¶åˆ¤æ–­æ˜¯å¦æ­£ç¡®ã€‚

è¾“å‡º JSON:
{{
"correct_answer_and_analyse":"...",
    "user_answer": "...",
    "is_correct": true æˆ– false
}}
"""
        messages = [{
            "role": "user",
            "content": [
                {"image": f"file://{os.path.abspath(image_path)}"},
                {"text": prompt}
            ]
        }]

        response = MultiModalConversation.call(
            model='qwen-vl-plus',
            messages=messages,
            api_key=self.dashscope_api_key,
            result_format='message'
        )

        raw_output = response.output.choices[0].message.content[0]['text']
        parsed = json.loads(self._clean_json_for_object(raw_output))
        
        return {
            'user_answer': parsed.get("user_answer", "").strip(),
            'is_correct': parsed.get("is_correct", False)
        }

    def generate_note_from_text(self, text, subject='General'):
        """
        ä»æ–‡æœ¬ç”Ÿæˆç»“æ„åŒ–ç¬”è®°
        
        Args:
            text: è¾“å…¥æ–‡æœ¬ï¼ˆè¯­éŸ³è½¬æ–‡å­—æˆ–æ‰‹åŠ¨è¾“å…¥ï¼‰
            subject: ç§‘ç›®åç§°
            
        Returns:
            dict: åŒ…å« title, summary, key_points, examples, detailed_notes, tags
        """
        subject_instruction = f'Subject is: {subject}' if subject else 'Please identify the subject'
        
        prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±æ•™å¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹å­¦ä¹ å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„å­¦ä¹ ç¬”è®°ã€‚

å­¦ä¹ å†…å®¹ï¼š
{text}

{subject_instruction}

è¯·ä¸¥æ ¼è¾“å‡º JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{{
  "title": "ç¬”è®°æ ‡é¢˜ï¼ˆç®€æ´æ˜äº†ï¼‰",
  "summary": "å†…å®¹æ‘˜è¦ï¼ˆ50-100å­—ï¼‰",
  "key_points": ["å…³é”®ç‚¹1", "å…³é”®ç‚¹2", "å…³é”®ç‚¹3"],
  "examples": ["ç¤ºä¾‹1", "ç¤ºä¾‹2"],
  "detailed_notes": "è¯¦ç»†ç¬”è®°å†…å®¹ï¼ˆMarkdownæ ¼å¼ï¼ŒåŒ…å«æ ‡é¢˜ã€åˆ—è¡¨ã€é‡ç‚¹ç­‰ï¼‰",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"]
}}

æ³¨æ„ï¼š
1. key_points åº”æå–æœ€æ ¸å¿ƒçš„3-5ä¸ªè¦ç‚¹
2. examples å¦‚æœæœ‰ï¼Œæå–1-3ä¸ªä»£è¡¨æ€§ç¤ºä¾‹ï¼Œå¦‚æœæ²¡æœ‰å¯ä»¥ä¸ºç©ºæ•°ç»„
3. detailed_notes ä½¿ç”¨ Markdown æ ¼å¼ï¼Œæ¸…æ™°åˆ†æ®µ
4. tags åº”åŒ…å«ç›¸å…³çš„çŸ¥è¯†ç‚¹æ ‡ç­¾
5. åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–è§£é‡Š"""

        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                stream=False,
                temperature=0.7,
                max_tokens=2000
            )
            
            raw_output = response.choices[0].message.content.strip()
            
            # æ¸…ç† Markdown ä»£ç å—
            if raw_output.startswith('```json'):
                raw_output = raw_output.replace('```json', '').replace('```', '').strip()
            elif raw_output.startswith('```'):
                raw_output = raw_output.replace('```', '').strip()
            
            parsed = json.loads(raw_output)
            
            return {
                'title': parsed.get('title', 'Untitled Note'),
                'summary': parsed.get('summary', ''),
                'key_points': parsed.get('key_points', []),
                'examples': parsed.get('examples', []),
                'detailed_notes': parsed.get('detailed_notes', text),
                'tags': parsed.get('tags', [])
            }
            
        except Exception as e:
            print(f"Error generating note: {e}")
            # è¿”å›é™çº§ç‰ˆæœ¬
            return self._fallback_note(text, subject)
    
    def _fallback_note(self, text, subject):
        """ç”Ÿæˆé™çº§ç‰ˆç¬”è®°"""
        sentences = [s.strip() for s in text.split('ã€‚') if s.strip()]
        key_points = sentences[:min(3, len(sentences))]
        title = sentences[0][:15] + "..." if sentences else "Note"
        summary = text[:100] + "..." if len(text) > 100 else text
        
        return {
            'title': title,
            'summary': summary,
            'key_points': key_points,
            'examples': [],
            'detailed_notes': text,
            'tags': [subject, 'study note'] if subject and subject != 'General' else ['study note']
        }
    
    def ocr_image(self, image_path):
        """
        ä½¿ç”¨ Qwen-VL è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶ç»å¯¹è·¯å¾„
            
        Returns:
            tuple: (text, error_message)
                - text: è¯†åˆ«å‡ºçš„æ–‡å­—å†…å®¹ï¼Œå¤±è´¥æ—¶ä¸º None
                - error_message: é”™è¯¯ä¿¡æ¯ï¼ŒæˆåŠŸæ—¶ä¸º None
        """
        try:
            prompt = (
                "è¯·ä»”ç»†è¯†åˆ«è¿™å¼ å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ã€‚\n"
                "è¦æ±‚ï¼š\n"
                "1. å®Œæ•´æå–æ‰€æœ‰å¯è§æ–‡å­—\n"
                "2. ä¿æŒåŸæœ‰çš„æ®µè½ç»“æ„\n"
                "3. å¦‚æœæœ‰æ ‡é¢˜ã€åˆ—è¡¨ç­‰ï¼Œè¯·ä¿ç•™æ ¼å¼\n"
                "4. åªè¾“å‡ºè¯†åˆ«åˆ°çš„æ–‡å­—å†…å®¹ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Š\n"
            )
            messages = [{
                "role": "user",
                "content": [
                    {"image": f"file://{os.path.abspath(image_path)}"},
                    {"text": prompt}
                ]
            }]
            
            response = MultiModalConversation.call(
                model='qwen-vl-plus',
                messages=messages,
                api_key=self.dashscope_api_key,
                result_format='message'
            )
            
            if response.status_code != 200:
                return None, f"OCR API Error {response.code}: {response.message}"
            
            text = response.output.choices[0].message.content[0]['text']
            return text.strip(), None
            
        except Exception as e:
            print(f"OCR failed: {e}")
            return None, f"å›¾ç‰‡OCRå¤±è´¥: {str(e)}"
    
    def speech_to_text(self, audio_data, language='auto'):
        """
        Speech to text using Xfyun ASR
        
        Args:
            audio_data: Raw PCM audio data (16kHz, mono, 16-bit)
            language: 'zh_cn' (Chinese), 'en_us' (English), or 'auto' (detect automatically)
        
        Returns:
            tuple: (recognized_text, error)
        """
        import logging
        
        # Auto-detection: try both languages and select best result
        if language == 'auto':
            logging.debug('Auto-detection mode: trying Chinese recognition...')
            text_zh, error_zh = self._recognize_xfyun(audio_data, 'zh_cn')
            zh_len = len(text_zh) if text_zh else 0
            logging.debug(f'Chinese result: {zh_len} characters')
            
            logging.debug('Trying English recognition...')
            text_en, error_en = self._recognize_xfyun(audio_data, 'en_us')
            en_len = len(text_en) if text_en else 0
            logging.debug(f'English result: {en_len} characters')
            
            if text_zh and text_en:
                # Calculate language confidence based on character composition
                en_letter_count = sum(1 for c in text_en if c.isalpha())
                en_ratio = en_letter_count / len(text_en) if text_en else 0
                
                zh_char_count = sum(1 for c in text_zh if '\u4e00' <= c <= '\u9fff')
                zh_ratio = zh_char_count / len(text_zh) if text_zh else 0
                
                logging.debug(f'Chinese ratio: {zh_ratio*100:.1f}%, English ratio: {en_ratio*100:.1f}%')
                
                if en_ratio > 0.6 and en_len > zh_len * 0.5:
                    logging.debug('Selecting English result')
                    return text_en, None
                else:
                    logging.debug('Selecting Chinese result')
                    return text_zh, None
            
            elif text_en:
                return text_en, None
            elif text_zh:
                return text_zh, None
            else:
                return None, error_zh or error_en or "Recognition failed"
        
        # Single language mode
        return self._recognize_xfyun(audio_data, language)
    
    def _recognize_xfyun(self, audio_data, language='zh_cn'):
        """Internal method: Recognize audio using Xfyun ASR."""
        import os
        
        # Get credentials from environment
        XFYUN_APPID = os.getenv('XFYUN_APPID', 'f047ebc8')
        XFYUN_API_SECRET = os.getenv('XFYUN_API_SECRET', 'M2MxZmM2MDdiYmYwNjlhYzFkNDdmOWZi')
        XFYUN_API_KEY = os.getenv('XFYUN_API_KEY', '014159c78a774f99e8e49946b4757daa')
        
        asr = _XfyunASRClient(audio_data, language, XFYUN_APPID, XFYUN_API_KEY, XFYUN_API_SECRET)
        return asr.recognize()


# Xfyun WebSocket ASR Client (Internal Class)
class _XfyunASRClient:
    """Xfyun WebSocket ASR Client - Internal implementation."""

    def __init__(self, audio_data, language, appid, api_key, api_secret):
        self.audio_data = audio_data
        self.language = language
        self.appid = appid
        self.api_key = api_key
        self.api_secret = api_secret
        self.result = []
        self.is_finished = False
        self.error = None

    def on_message(self, ws, message):
        import json
        try:
            data = json.loads(message)
            code = data.get("code")

            if code != 0:
                self.error = f"Xfyun Error {code}: {data.get('message', 'Unknown error')}"
                self.is_finished = True
                ws.close()
                return

            result_data = data.get("data", {})
            result = result_data.get("result", {})

            pgs = result.get("pgs", "")
            rg = result.get("rg", [])

            ws_list = result.get("ws", [])
            current_text = ""
            for ws_item in ws_list:
                cw_list = ws_item.get("cw", [])
                for cw in cw_list:
                    word = cw.get("w", "")
                    if word:
                        current_text += word

            if pgs == "rpl" and len(rg) == 2:
                start_idx = rg[0]
                end_idx = rg[1]
                if start_idx < len(self.result):
                    self.result = self.result[:start_idx]
                if current_text:
                    self.result.append(current_text)
            elif pgs == "apd" or not pgs:
                if current_text:
                    self.result.append(current_text)

            status = result_data.get("status")
            if status == 2:
                self.is_finished = True
                ws.close()

        except Exception as e:
            self.error = str(e)
            self.is_finished = True
            ws.close()

    def on_error(self, ws, error):
        self.error = str(error)
        self.is_finished = True

    def on_close(self, ws, close_status_code, close_msg):
        self.is_finished = True

    def on_open(self, ws):
        import threading
        import time
        import json
        import base64
        
        def send_audio():
            try:
                frame_size = 1280
                interval = 0.04

                status = 0
                offset = 0
                total_len = len(self.audio_data)

                while offset < total_len:
                    end = min(offset + frame_size, total_len)
                    chunk = self.audio_data[offset:end]

                    if offset == 0:
                        status = 0
                    elif end >= total_len:
                        status = 2
                    else:
                        status = 1

                    audio_base64 = base64.b64encode(chunk).decode('utf-8')

                    if status == 0:
                        message = {
                            "common": {"app_id": self.appid},
                            "business": {
                                "language": self.language,
                                "domain": "iat",
                                "accent": "mandarin",
                                "vad_eos": 3000,
                                "ptt": 1
                            },
                            "data": {
                                "status": status,
                                "format": "audio/L16;rate=16000",
                                "encoding": "raw",
                                "audio": audio_base64
                            }
                        }
                    else:
                        message = {
                            "data": {
                                "status": status,
                                "format": "audio/L16;rate=16000",
                                "encoding": "raw",
                                "audio": audio_base64
                            }
                        }

                    ws.send(json.dumps(message))
                    offset = end

                    if status != 2:
                        time.sleep(interval)

            except Exception as e:
                self.error = str(e)
                ws.close()

        threading.Thread(target=send_audio).start()

    def recognize(self):
        import websocket
        import time
        
        try:
            url = self._create_auth_url()

            ws = websocket.WebSocketApp(
                url,
                on_message=self.on_message,
                on_error=self.on_error,
                on_close=self.on_close,
                on_open=self.on_open
            )

            ws.run_forever()

            timeout = 60
            start_time = time.time()
            while not self.is_finished and (time.time() - start_time) < timeout:
                time.sleep(0.1)

            if self.error:
                return None, self.error

            return ''.join(self.result), None

        except Exception as e:
            return None, str(e)
    
    def _create_auth_url(self):
        """Create Xfyun WebSocket authentication URL."""
        import base64
        import hmac
        import hashlib
        from datetime import datetime
        from time import mktime
        from wsgiref.handlers import format_date_time
        from urllib.parse import urlencode

        now = datetime.now()
        date = format_date_time(mktime(now.timetuple()))

        signature_origin = f"host: ws-api.xfyun.cn\ndate: {date}\nGET /v2/iat HTTP/1.1"

        signature_sha = hmac.new(
            self.api_secret.encode('utf-8'),
            signature_origin.encode('utf-8'),
            digestmod=hashlib.sha256
        ).digest()

        signature_sha_base64 = base64.b64encode(signature_sha).decode('utf-8')

        authorization_origin = f'api_key="{self.api_key}", algorithm="hmac-sha256", headers="host date request-line", signature="{signature_sha_base64}"'
        authorization = base64.b64encode(authorization_origin.encode('utf-8')).decode('utf-8')

        params = {
            "authorization": authorization,
            "date": date,
            "host": "ws-api.xfyun.cn"
        }

        url = f"wss://ws-api.xfyun.cn/v2/iat?{urlencode(params)}"
        return url


# åˆ›å»ºå•ä¾‹å®ä¾‹
ai_service = AIService()
